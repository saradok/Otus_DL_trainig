{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from utils import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "       \n",
    "        break\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Net()\n",
    "output = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_p_cross_entrophy(outputs,targets):\n",
    "    # применяем функцию софтмакс для выходов поданного на вход ф-ции слоя\n",
    "    \n",
    "    qq,_=torch.max(outputs,1,keepdim=True)\n",
    "\n",
    "    exps=torch.exp(outputs-qq)\n",
    "    own_sm=exps/torch.sum(exps,1,keepdim=True)\n",
    "    \n",
    "    # делаем расчет перекрестной энтропии\n",
    "    m=targets.shape[0]\n",
    "    p=own_sm\n",
    "    log_likelihood=-torch.log(p[range(m),targets])\n",
    "    loss=torch.sum(log_likelihood)/m\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3543)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_p_cross_entrophy(output,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1053,  0.0889,  0.1205,  0.0826,  0.1102,  0.1354,  0.0626,\n",
       "          0.1075,  0.0823,  0.1047],\n",
       "        [ 0.1053,  0.0882,  0.1196,  0.0848,  0.1083,  0.1377,  0.0627,\n",
       "          0.1067,  0.0829,  0.1037],\n",
       "        [ 0.1062,  0.0877,  0.1201,  0.0827,  0.1096,  0.1351,  0.0635,\n",
       "          0.1072,  0.0831,  0.1046],\n",
       "        [ 0.1055,  0.0882,  0.1194,  0.0824,  0.1095,  0.1363,  0.0633,\n",
       "          0.1071,  0.0823,  0.1059],\n",
       "        [ 0.1057,  0.0881,  0.1194,  0.0815,  0.1094,  0.1365,  0.0640,\n",
       "          0.1067,  0.0828,  0.1059],\n",
       "        [ 0.1057,  0.0876,  0.1201,  0.0819,  0.1102,  0.1351,  0.0633,\n",
       "          0.1071,  0.0827,  0.1063],\n",
       "        [ 0.1063,  0.0876,  0.1205,  0.0810,  0.1104,  0.1379,  0.0625,\n",
       "          0.1053,  0.0829,  0.1056],\n",
       "        [ 0.1055,  0.0877,  0.1200,  0.0822,  0.1084,  0.1373,  0.0642,\n",
       "          0.1065,  0.0832,  0.1051],\n",
       "        [ 0.1064,  0.0883,  0.1197,  0.0824,  0.1095,  0.1368,  0.0629,\n",
       "          0.1057,  0.0821,  0.1061],\n",
       "        [ 0.1046,  0.0878,  0.1209,  0.0827,  0.1100,  0.1371,  0.0622,\n",
       "          0.1075,  0.0831,  0.1041],\n",
       "        [ 0.1034,  0.0883,  0.1212,  0.0829,  0.1079,  0.1352,  0.0640,\n",
       "          0.1079,  0.0838,  0.1054],\n",
       "        [ 0.1067,  0.0880,  0.1192,  0.0829,  0.1092,  0.1349,  0.0639,\n",
       "          0.1070,  0.0828,  0.1054],\n",
       "        [ 0.1048,  0.0873,  0.1187,  0.0832,  0.1103,  0.1367,  0.0639,\n",
       "          0.1069,  0.0833,  0.1049],\n",
       "        [ 0.1063,  0.0871,  0.1197,  0.0812,  0.1100,  0.1379,  0.0634,\n",
       "          0.1076,  0.0827,  0.1040],\n",
       "        [ 0.1057,  0.0872,  0.1215,  0.0821,  0.1098,  0.1370,  0.0624,\n",
       "          0.1071,  0.0818,  0.1053],\n",
       "        [ 0.1068,  0.0859,  0.1189,  0.0826,  0.1106,  0.1387,  0.0630,\n",
       "          0.1049,  0.0826,  0.1061],\n",
       "        [ 0.1058,  0.0873,  0.1182,  0.0844,  0.1098,  0.1373,  0.0632,\n",
       "          0.1052,  0.0825,  0.1063],\n",
       "        [ 0.1049,  0.0883,  0.1205,  0.0830,  0.1096,  0.1357,  0.0628,\n",
       "          0.1082,  0.0834,  0.1036],\n",
       "        [ 0.1049,  0.0869,  0.1201,  0.0825,  0.1099,  0.1370,  0.0633,\n",
       "          0.1064,  0.0827,  0.1062],\n",
       "        [ 0.1073,  0.0885,  0.1194,  0.0812,  0.1101,  0.1366,  0.0627,\n",
       "          0.1068,  0.0829,  0.1045],\n",
       "        [ 0.1047,  0.0870,  0.1198,  0.0829,  0.1115,  0.1366,  0.0626,\n",
       "          0.1085,  0.0814,  0.1048],\n",
       "        [ 0.1039,  0.0881,  0.1213,  0.0836,  0.1092,  0.1360,  0.0631,\n",
       "          0.1066,  0.0830,  0.1053],\n",
       "        [ 0.1064,  0.0871,  0.1179,  0.0829,  0.1091,  0.1400,  0.0633,\n",
       "          0.1062,  0.0809,  0.1061],\n",
       "        [ 0.1056,  0.0874,  0.1194,  0.0822,  0.1087,  0.1378,  0.0637,\n",
       "          0.1072,  0.0825,  0.1055],\n",
       "        [ 0.1046,  0.0865,  0.1195,  0.0809,  0.1084,  0.1366,  0.0642,\n",
       "          0.1082,  0.0828,  0.1083],\n",
       "        [ 0.1074,  0.0870,  0.1169,  0.0811,  0.1088,  0.1393,  0.0629,\n",
       "          0.1077,  0.0820,  0.1068],\n",
       "        [ 0.1060,  0.0870,  0.1179,  0.0820,  0.1087,  0.1385,  0.0636,\n",
       "          0.1078,  0.0819,  0.1066],\n",
       "        [ 0.1047,  0.0877,  0.1207,  0.0832,  0.1099,  0.1374,  0.0631,\n",
       "          0.1065,  0.0832,  0.1037],\n",
       "        [ 0.1064,  0.0881,  0.1197,  0.0834,  0.1089,  0.1367,  0.0624,\n",
       "          0.1064,  0.0823,  0.1057],\n",
       "        [ 0.1076,  0.0883,  0.1194,  0.0809,  0.1096,  0.1368,  0.0627,\n",
       "          0.1066,  0.0832,  0.1049],\n",
       "        [ 0.1052,  0.0862,  0.1188,  0.0831,  0.1098,  0.1372,  0.0632,\n",
       "          0.1064,  0.0828,  0.1074],\n",
       "        [ 0.1058,  0.0879,  0.1190,  0.0826,  0.1091,  0.1367,  0.0628,\n",
       "          0.1083,  0.0832,  0.1046],\n",
       "        [ 0.1064,  0.0871,  0.1183,  0.0814,  0.1088,  0.1382,  0.0635,\n",
       "          0.1071,  0.0830,  0.1061],\n",
       "        [ 0.1071,  0.0868,  0.1172,  0.0819,  0.1089,  0.1396,  0.0633,\n",
       "          0.1074,  0.0818,  0.1061],\n",
       "        [ 0.1059,  0.0871,  0.1196,  0.0818,  0.1109,  0.1363,  0.0632,\n",
       "          0.1073,  0.0825,  0.1054],\n",
       "        [ 0.1058,  0.0876,  0.1190,  0.0810,  0.1102,  0.1374,  0.0630,\n",
       "          0.1074,  0.0832,  0.1055],\n",
       "        [ 0.1085,  0.0876,  0.1176,  0.0821,  0.1104,  0.1386,  0.0617,\n",
       "          0.1072,  0.0822,  0.1041],\n",
       "        [ 0.1047,  0.0879,  0.1197,  0.0830,  0.1094,  0.1365,  0.0628,\n",
       "          0.1070,  0.0837,  0.1053],\n",
       "        [ 0.1060,  0.0864,  0.1188,  0.0830,  0.1087,  0.1383,  0.0632,\n",
       "          0.1066,  0.0815,  0.1075],\n",
       "        [ 0.1065,  0.0877,  0.1201,  0.0823,  0.1098,  0.1344,  0.0641,\n",
       "          0.1076,  0.0826,  0.1048],\n",
       "        [ 0.1059,  0.0883,  0.1189,  0.0821,  0.1100,  0.1375,  0.0633,\n",
       "          0.1075,  0.0821,  0.1043],\n",
       "        [ 0.1058,  0.0878,  0.1198,  0.0819,  0.1096,  0.1357,  0.0629,\n",
       "          0.1084,  0.0818,  0.1063],\n",
       "        [ 0.1053,  0.0877,  0.1197,  0.0826,  0.1103,  0.1365,  0.0625,\n",
       "          0.1073,  0.0829,  0.1052],\n",
       "        [ 0.1062,  0.0884,  0.1193,  0.0820,  0.1090,  0.1355,  0.0632,\n",
       "          0.1078,  0.0826,  0.1060],\n",
       "        [ 0.1073,  0.0885,  0.1195,  0.0818,  0.1076,  0.1371,  0.0640,\n",
       "          0.1061,  0.0831,  0.1050],\n",
       "        [ 0.1058,  0.0868,  0.1193,  0.0820,  0.1103,  0.1361,  0.0636,\n",
       "          0.1067,  0.0834,  0.1060],\n",
       "        [ 0.1058,  0.0889,  0.1198,  0.0818,  0.1080,  0.1366,  0.0629,\n",
       "          0.1063,  0.0842,  0.1058],\n",
       "        [ 0.1060,  0.0891,  0.1192,  0.0820,  0.1092,  0.1367,  0.0626,\n",
       "          0.1079,  0.0829,  0.1045],\n",
       "        [ 0.1062,  0.0862,  0.1195,  0.0825,  0.1101,  0.1363,  0.0636,\n",
       "          0.1065,  0.0839,  0.1050],\n",
       "        [ 0.1060,  0.0883,  0.1190,  0.0827,  0.1088,  0.1380,  0.0628,\n",
       "          0.1070,  0.0831,  0.1043]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(output,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3543)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.nll_loss(F.log_softmax(output,dim=1),target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
